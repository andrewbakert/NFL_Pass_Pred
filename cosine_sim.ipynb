{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# IMPORTING LOCAL MODULES\n",
    "import importlib\n",
    "import form_pred\n",
    "import ball_movement\n",
    "import get_data\n",
    "import def_clean\n",
    "import TrainTestNFL\n",
    "\n",
    "# REFRESHING LOCAL CHANGES\n",
    "importlib.reload(get_data)\n",
    "importlib.reload(form_pred)\n",
    "importlib.reload(def_clean)\n",
    "importlib.reload(ball_movement)\n",
    "importlib.reload(TrainTestNFL)\n",
    "\n",
    "# IMPORTING LOCAL PACKAGES\n",
    "from get_data import get_assets, get_positional_data\n",
    "from form_pred import clean_positional\n",
    "from ball_movement import ball_quadrants, make_quad_chart\n",
    "from def_clean import DefensiveCleaning\n",
    "from TrainTestNFL import TrainTestNFL\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class PrepPipe:\n",
    "    def __init__(self, first=1, last=14, n_cuts=11, frameLimit=11,\n",
    "                 simMethod='distance', quad_num=4, def_fp='assets/def_clean_output.csv'):\n",
    "        self.first = first\n",
    "        self.last = last\n",
    "        self.n_cuts = n_cuts\n",
    "        self.frameLimit = frameLimit\n",
    "        self.simMethod = simMethod\n",
    "        self.quad_num = quad_num\n",
    "        self.def_fp = def_fp\n",
    "        if not os.path.exists('Kaggle-Data-Files'):\n",
    "            get_assets()\n",
    "        self.positions = get_positional_data()\n",
    "\n",
    "    def clean_data(self):\n",
    "        quads = ball_quadrants(self.positions,self.quad_num)\n",
    "        offense = clean_positional(self.positions)\n",
    "        try:\n",
    "            defense = pd.read_csv(self.def_fp).reset_index()\n",
    "            if 2018123015 not in defense['gameId'].to_list():\n",
    "                print('missing full 17 week dataset')\n",
    "                print('getting dataset now.')\n",
    "                raise LookupError\n",
    "        except (FileNotFoundError, LookupError):\n",
    "            def_cleaning = DefensiveCleaning(weeks_data=self.positions, n_cuts=self.n_cuts,\n",
    "                                             frameLimit=self.frameLimit, simMethod=self.simMethod,\n",
    "                                             )\n",
    "            defense = def_cleaning.generate_full_df(1, 17, fp=self.def_fp).reset_index()\n",
    "        self.train_test = TrainTestNFL(offense,defense,quads)\n",
    "        X_train, X_test, y_train, y_test = self.train_test.split(self.first, self.last)\n",
    "        return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "import pickle\n",
    "from def_clust import return_pca_and_clusters\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "class OffensiveFormation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model=None, model_params=None, model_fp='models/off_form.pkl',\n",
    "                 cv=5, scoring='fi_micro'):\n",
    "        if not model:\n",
    "            self.model = LogisticRegression(max_iter=10000)\n",
    "        else:\n",
    "            self.model = model\n",
    "        if not model_params:\n",
    "            self.model_params = {'C': [10**x for x in range(-4, 4)]}\n",
    "        else:\n",
    "            self.model_params = model_params\n",
    "        self.model_fp = model_fp\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "\n",
    "    def fit(self, X):\n",
    "        if os.path.exists(self.model_fp):\n",
    "            with open(self.model_fp, 'rb') as model:\n",
    "                 self.grid = pickle.load(model)\n",
    "        else:\n",
    "            self.grid = GridSearchCV(self.model, param_grid=self.model_params, cv=self.cv,\n",
    "                                     scoring=self.scoring)\n",
    "            X_train = X.drop('offensiveFormation', axis=1)\n",
    "            y_train = X['offensiveFormation']\n",
    "            self.grid.fit(X_train, y_train)\n",
    "            base = self.model_fp.split('/')[0]\n",
    "            if not os.path.exists(base):\n",
    "                os.mkdir(base)\n",
    "            with open(self.model_fp, 'wb') as model:\n",
    "                pickle.dump(self.grid, model)\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.drop('offensiveFormation', axis=1)\n",
    "        y = self.grid.predict(X)\n",
    "        X['offensiveFormation'] = y\n",
    "        return X\n",
    "\n",
    "\n",
    "class DefensiveClustering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns='all', n_clusters=5, pca_variance=0.8):\n",
    "        self.columns = columns\n",
    "        self.n_clusters = n_clusters\n",
    "        self.pca_variance = pca_variance\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        actions = [action for action in X.columns if '_act' in action]\n",
    "        self.melt_cols = ['gameId','playId'] + actions\n",
    "\n",
    "        melt_df = X[self.melt_cols]\n",
    "        melt_df = melt_df.melt(['gameId','playId']).dropna()\n",
    "        melt_df = melt_df.groupby(['gameId','playId','value']).count()\n",
    "        melt_df = melt_df.reset_index().pivot(index=['gameId','playId'],\n",
    "                                              columns='value',values='variable').fillna(0)\n",
    "        melt_df['TOT'] = melt_df['B'] + melt_df['M'] + melt_df['Z']\n",
    "        melt_df['%B'] = melt_df['B'] / melt_df['TOT']\n",
    "        melt_df['%M'] = melt_df['M'] / melt_df['TOT']\n",
    "        melt_df['%Z'] = melt_df['Z'] / melt_df['TOT']\n",
    "        melt_df = melt_df.fillna(0)\n",
    "\n",
    "        self.orig_cols =  ['gameId','playId','defendersInTheBox','extra_blitzers','on_line_coverage','numberOfPassRushers','DB','LB','DL','yardline_first','yardline_100']\n",
    "        orig_df = X[self.orig_cols].set_index(['gameId','playId'])\n",
    "\n",
    "        orig_df = orig_df.merge(melt_df[['%B','%M','%Z']], on=['gameId','playId']).fillna(0)\n",
    "        self.scaler = StandardScaler()\n",
    "        X = self.scaler.fit_transform(orig_df)\n",
    "        self.pca = PCA(n_components=self.pca_variance)\n",
    "        scores_pca = self.pca.fit_transform(X)\n",
    "        comps_pca = self.pca.components_\n",
    "        self.kmeans_pca = KMeans(n_clusters=self.n_clusters, init='k-means++', random_state=42)\n",
    "        kmeans_labels = self.kmeans_pca.fit_transform(scores_pca)\n",
    "        pca_df = pd.DataFrame(scores_pca, columns=[f'pc_{i}' for i in range(scores_pca.shape[1])])\n",
    "        df_seg = pd.concat([X.reset_index()[['gameId','playId']], pca_df], axis=1)\n",
    "        df_seg['cluster'] = kmeans_labels\n",
    "        return df_seg\n",
    "\n",
    "    def fit(self, X):\n",
    "        melt_df = pd.DataFrame()\n",
    "        for col in self.melt_cols:\n",
    "            if col in X.columns:\n",
    "                melt_df[col] = X[col]\n",
    "            else:\n",
    "                melt_df[col] = np.nan\n",
    "        melt_df = melt_df.melt(['gameId','playId']).dropna()\n",
    "        melt_df = melt_df.groupby(['gameId','playId','value']).count()\n",
    "        melt_df = melt_df.reset_index().pivot(index=['gameId','playId'],\n",
    "                                              columns='value',values='variable').fillna(0)\n",
    "        melt_df['TOT'] = melt_df['B'] + melt_df['M'] + melt_df['Z']\n",
    "        melt_df['%B'] = melt_df['B'] / melt_df['TOT']\n",
    "        melt_df['%M'] = melt_df['M'] / melt_df['TOT']\n",
    "        melt_df['%Z'] = melt_df['Z'] / melt_df['TOT']\n",
    "        melt_df = melt_df.fillna(0)\n",
    "        orig_df = X[self.orig_cols].set_index(['gameId','playId'])\n",
    "        orig_df = orig_df.merge(melt_df[['%B','%M','%Z']], on=['gameId','playId']).fillna(0)\n",
    "        X = self.scaler.transform(orig_df)\n",
    "        scores_pca = self.pca.transform(X)\n",
    "        kmeans_labels = self.kmeans_pca.transform(scores_pca)\n",
    "        pca_df = pd.DataFrame(scores_pca, columns=[f'pc_{i}' for i in range(scores_pca.shape[1])])\n",
    "        df_seg = pd.concat([X.reset_index()[['gameId','playId']], pca_df], axis=1)\n",
    "        df_seg['cluster'] = kmeans_labels\n",
    "        return df_seg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional data already downloaded.\n",
      "reading positional data.\n",
      "returning positional data.\n"
     ]
    }
   ],
   "source": [
    "prep_pipe = PrepPipe()\n",
    "X_train, X_test, y_train, y_test = prep_pipe.clean_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['FBL0_x',\n 'FBR0_x',\n 'HBL0_x',\n 'HBL1_x',\n 'HBR0_x',\n 'HBR1_x',\n 'QB0_x',\n 'QB1_x',\n 'RBL0_x',\n 'RBL1_x',\n 'RBL2_x',\n 'RBR0_x',\n 'RBR1_x',\n 'RBR2_x',\n 'TEL0_x',\n 'TEL1_x',\n 'TEL2_x',\n 'TER0_x',\n 'TER1_x',\n 'TER2_x',\n 'WRL0_x',\n 'WRL1_x',\n 'WRL2_x',\n 'WRL3_x',\n 'WRR0_x',\n 'WRR1_x',\n 'WRR2_x',\n 'WRR3_x',\n 'FBL0_y',\n 'FBR0_y',\n 'HBL0_y',\n 'HBL1_y',\n 'HBR0_y',\n 'HBR1_y',\n 'QB0_y',\n 'QB1_y',\n 'RBL0_y',\n 'RBL1_y',\n 'RBL2_y',\n 'RBR0_y',\n 'RBR1_y',\n 'RBR2_y',\n 'TEL0_y',\n 'TEL1_y',\n 'TEL2_y',\n 'TER0_y',\n 'TER1_y',\n 'TER2_y',\n 'WRL0_y',\n 'WRL1_y',\n 'WRL2_y',\n 'WRL3_y',\n 'WRR0_y',\n 'WRR1_y',\n 'WRR2_y',\n 'WRR3_y',\n 'FBL0_in',\n 'FBR0_in',\n 'HBL0_in',\n 'HBL1_in',\n 'HBR0_in',\n 'HBR1_in',\n 'QB0_in',\n 'QB1_in',\n 'RBL0_in',\n 'RBL1_in',\n 'RBL2_in',\n 'RBR0_in',\n 'RBR1_in',\n 'RBR2_in',\n 'TEL0_in',\n 'TEL1_in',\n 'TEL2_in',\n 'TER0_in',\n 'TER1_in',\n 'TER2_in',\n 'WRL0_in',\n 'WRL1_in',\n 'WRL2_in',\n 'WRL3_in',\n 'WRR0_in',\n 'WRR1_in',\n 'WRR2_in',\n 'WRR3_in',\n 'gameId',\n 'playId',\n 'offenseFormation',\n 'gamePlayId',\n 'perc_left',\n 'perc_right',\n 'perc_behind_los',\n 'FB',\n 'HB',\n 'QB',\n 'RB',\n 'TE',\n 'WR',\n 'week',\n 'index',\n 'defendersInTheBox',\n 'numberOfPassRushers',\n 'DB',\n 'LB',\n 'DL',\n 'yardline_first_dir',\n 'yardline_100_dir',\n 'CBL0_act',\n 'CBL0_x_start',\n 'CBL0_y_start',\n 'CBL1_act',\n 'CBL1_x_start',\n 'CBL1_y_start',\n 'CBL2_act',\n 'CBL2_x_start',\n 'CBL2_y_start',\n 'CBL3_act',\n 'CBL3_x_start',\n 'CBL3_y_start',\n 'CBR0_act',\n 'CBR0_x_start',\n 'CBR0_y_start',\n 'CBR1_act',\n 'CBR1_x_start',\n 'CBR1_y_start',\n 'CBR2_act',\n 'CBR2_x_start',\n 'CBR2_y_start',\n 'CBR3_act',\n 'CBR3_x_start',\n 'CBR3_y_start',\n 'DBL0_act',\n 'DBL0_x_start',\n 'DBL0_y_start',\n 'DBL1_act',\n 'DBL1_x_start',\n 'DBL1_y_start',\n 'DBL2_act',\n 'DBL2_x_start',\n 'DBL2_y_start',\n 'DBL3_act',\n 'DBL3_x_start',\n 'DBL3_y_start',\n 'DBR0_act',\n 'DBR0_x_start',\n 'DBR0_y_start',\n 'DBR1_act',\n 'DBR1_x_start',\n 'DBR1_y_start',\n 'DBR2_act',\n 'DBR2_x_start',\n 'DBR2_y_start',\n 'DEL0_act',\n 'DEL0_x_start',\n 'DEL0_y_start',\n 'DER0_act',\n 'DER0_x_start',\n 'DER0_y_start',\n 'DLL0_act',\n 'DLL0_x_start',\n 'DLL0_y_start',\n 'DLR0_act',\n 'DLR0_x_start',\n 'DLR0_y_start',\n 'FSL0_act',\n 'FSL0_x_start',\n 'FSL0_y_start',\n 'FSL1_act',\n 'FSL1_x_start',\n 'FSL1_y_start',\n 'FSL2_act',\n 'FSL2_x_start',\n 'FSL2_y_start',\n 'FSR0_act',\n 'FSR0_x_start',\n 'FSR0_y_start',\n 'FSR1_act',\n 'FSR1_x_start',\n 'FSR1_y_start',\n 'FSR2_act',\n 'FSR2_x_start',\n 'FSR2_y_start',\n 'ILBL0_act',\n 'ILBL0_x_start',\n 'ILBL0_y_start',\n 'ILBL1_act',\n 'ILBL1_x_start',\n 'ILBL1_y_start',\n 'ILBL2_act',\n 'ILBL2_x_start',\n 'ILBL2_y_start',\n 'ILBR0_act',\n 'ILBR0_x_start',\n 'ILBR0_y_start',\n 'ILBR1_act',\n 'ILBR1_x_start',\n 'ILBR1_y_start',\n 'ILBR2_act',\n 'ILBR2_x_start',\n 'ILBR2_y_start',\n 'LBL0_act',\n 'LBL0_x_start',\n 'LBL0_y_start',\n 'LBL1_act',\n 'LBL1_x_start',\n 'LBL1_y_start',\n 'LBL2_act',\n 'LBL2_x_start',\n 'LBL2_y_start',\n 'LBR0_act',\n 'LBR0_x_start',\n 'LBR0_y_start',\n 'LBR1_act',\n 'LBR1_x_start',\n 'LBR1_y_start',\n 'LBR2_act',\n 'LBR2_x_start',\n 'LBR2_y_start',\n 'MLBL0_act',\n 'MLBL0_x_start',\n 'MLBL0_y_start',\n 'MLBL1_act',\n 'MLBL1_x_start',\n 'MLBL1_y_start',\n 'MLBR0_act',\n 'MLBR0_x_start',\n 'MLBR0_y_start',\n 'MLBR1_act',\n 'MLBR1_x_start',\n 'MLBR1_y_start',\n 'NTL0_act',\n 'NTL0_x_start',\n 'NTL0_y_start',\n 'OLBL0_act',\n 'OLBL0_x_start',\n 'OLBL0_y_start',\n 'OLBL1_act',\n 'OLBL1_x_start',\n 'OLBL1_y_start',\n 'OLBL2_act',\n 'OLBL2_x_start',\n 'OLBL2_y_start',\n 'OLBL3_act',\n 'OLBL3_x_start',\n 'OLBL3_y_start',\n 'OLBR0_act',\n 'OLBR0_x_start',\n 'OLBR0_y_start',\n 'OLBR1_act',\n 'OLBR1_x_start',\n 'OLBR1_y_start',\n 'OLBR2_act',\n 'OLBR2_x_start',\n 'OLBR2_y_start',\n 'OLBR3_act',\n 'OLBR3_x_start',\n 'OLBR3_y_start',\n 'SL0_act',\n 'SL0_x_start',\n 'SL0_y_start',\n 'SL1_act',\n 'SL1_x_start',\n 'SL1_y_start',\n 'SR0_act',\n 'SR0_x_start',\n 'SR0_y_start',\n 'SR1_act',\n 'SR1_x_start',\n 'SR1_y_start',\n 'SSL0_act',\n 'SSL0_x_start',\n 'SSL0_y_start',\n 'SSL1_act',\n 'SSL1_x_start',\n 'SSL1_y_start',\n 'SSL2_act',\n 'SSL2_x_start',\n 'SSL2_y_start',\n 'SSR0_act',\n 'SSR0_x_start',\n 'SSR0_y_start',\n 'SSR1_act',\n 'SSR1_x_start',\n 'SSR1_y_start',\n 'SSR2_act',\n 'SSR2_x_start',\n 'SSR2_y_start',\n 'yardsToGo']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}