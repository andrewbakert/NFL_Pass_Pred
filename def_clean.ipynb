{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................initializing\n"
     ]
    }
   ],
   "source": [
    "print('..............................initializing')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_time(df):\n",
    "        #df = df[df['playId']==2372]\n",
    "        \n",
    "        time = df[['gameId','playId','time']]\n",
    "\n",
    "        df['key'] = df['gameId'].astype(str) + df['playId'].astype(str) + df['time'].astype(str) + df['nflId'].astype(str)\n",
    "\n",
    "        man_ms = df.groupby('key').cumcount()\n",
    "\n",
    "        fb_df = df[df['nflId'].isnull()]\n",
    "\n",
    "        tot_ms = fb_df[['gameId','playId','time','event']].groupby(by=['gameId','playId','time']).count()\n",
    "\n",
    "        time_df = pd.concat([time, man_ms], axis=1).rename(columns={0:'new_sec'})\n",
    "        \n",
    "        tot_ms = tot_ms.reset_index()\n",
    "\n",
    "        time_df = time_df.reset_index().merge(tot_ms, on=['gameId','playId','time']).set_index('index')\n",
    "\n",
    "        time_df['new_sec'] = 10 - time_df['event'] + time_df['new_sec']\n",
    "\n",
    "        time_df['check'] = time_df.time.str[20:21]\n",
    "        \n",
    "        time_df['man_time'] = time_df.time.str[:20] + time_df['new_sec'].astype(str) + '00Z'\n",
    "\n",
    "        time_df['new_time'] = np.where(time_df['check']!=time_df['new_sec'], time_df['man_time'], time_df['time'])\n",
    "\n",
    "        time = time_df['new_time']\n",
    "\n",
    "        df = df.reset_index().merge(time, on='index').set_index('index').drop(columns=['key','time']).rename(columns={'new_time':'time'})\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def filter_full_position_df(df, frameLimit):\n",
    "\n",
    "    #df = new_time(week_data)\n",
    "    \n",
    "    fb_df = df[df['nflId'].isnull()]\n",
    "    pos_df = df[df['nflId'].notnull()]\n",
    "        \n",
    "    fb_df['time'] =  pd.to_datetime(fb_df['time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "    \n",
    "    # Find time that pass was thrown and merge with main df.\n",
    "    pass_start = fb_df[fb_df['event'] == 'pass_forward'][['gameId', 'playId', 'frameId']].rename({'frameId': 'frame_pass'}, axis=1)\n",
    "    \n",
    "    ball_snap = fb_df[fb_df['event'] == 'ball_snap'][['gameId', 'playId', 'frameId']].rename({'frameId': 'frame_snap'}, axis=1)\n",
    "\n",
    "    pos_df = pos_df.merge(pass_start, on=['gameId', 'playId'], how='left')\n",
    "    pos_df = pos_df.merge(ball_snap, on=['gameId', 'playId'], how='left')\n",
    "\n",
    "    # Convert time to datetime format.\n",
    "    pos_df['time'] = pd.to_datetime(pos_df['time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    # Find whether part of play was before pass.\n",
    "    pos_df['before_pass'] = pos_df['frameId'].le(pos_df['frame_pass'])\n",
    "    pos_df['after_snap'] = pos_df['frameId'].ge(pos_df['frame_snap'])\n",
    "\n",
    "    # Filter to include only part of play before pass.\n",
    "    pos_df = pos_df[pos_df['before_pass']]\n",
    "    pos_df = pos_df[pos_df['after_snap']]\n",
    "\n",
    "    uniq_df = pos_df[['frameId','gameId','playId','event']]\n",
    "\n",
    "    uniq_df = uniq_df.groupby(by=['frameId','gameId','playId']).count().reset_index().drop(columns='event')\n",
    "\n",
    "    uniq_df = uniq_df.groupby(by=['gameId','playId']).count().sort_values(by='frameId').rename(columns={'frameId':'frameCount'})\n",
    "\n",
    "    pos_df = pos_df.merge(uniq_df.reset_index(), on=['gameId','playId'])\n",
    "\n",
    "    short_df = pos_df[pos_df['frameCount'] < frameLimit]\n",
    "    short_df = short_df[['gameId','playId','frameId']].groupby(by=['gameId','playId']).count().drop(columns='frameId')\n",
    "    \n",
    "    #short_df.to_csv('assets/short_plays.csv')\n",
    "    \n",
    "    pos_df = pos_df[pos_df['frameCount'] >= frameLimit]\n",
    "\n",
    "    return pos_df.drop(columns=['before_pass','after_snap'])\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#week_data = pd.read_csv('Kaggle-Data-Files/week1.csv')\n",
    "\n",
    "#filter_full_position_df(week_data, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(df, column, bins, hue, fig_name):\n",
    "    sns.histplot(data=df, x=column, bins=bins, hue=hue)\n",
    "    figure = 'assets/' + fig_name + '.png'\n",
    "    plt.savefig(figure)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rank(df, col, reverse=False):\n",
    "    \"\"\"\n",
    "    Find the ranking of a series based on values.\n",
    "    :param df: Dataframe for ranking; pd.DataFrame\n",
    "    :param col: Column from dataframe to rank; str\n",
    "    :param reverse: Flag of whether to reverse rank direction; bool\n",
    "    :return: Array with rankings; np.array\n",
    "    \"\"\"\n",
    "    # Extract series and use arsort to find rankings.\n",
    "    ser = df[col]\n",
    "    temp = np.argsort(ser)\n",
    "\n",
    "    # Reverse direction based on flag.\n",
    "    if reverse:\n",
    "        temp = temp[::-1]\n",
    "\n",
    "    # Fill ranking array.\n",
    "    ranks = np.empty_like(temp)\n",
    "    ranks[temp] = np.arange(ser.shape[0])\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_directions(df, play_data):\n",
    "    # Extract the time elapsed in the play. Labeled as \"time_acc_s\". May take a while for full dataset.\n",
    "    df['time_diff'] = df.groupby(['playId', 'gameId', 'displayName'])['time'].diff()\n",
    "    df['time_diff'][df['time_diff'].isnull()] = pd.Timedelta(0)\n",
    "    df['time_acc_s'] = df.groupby(['playId', 'gameId', 'displayName'])['time_diff'].transform(\n",
    "        lambda x: x.map(lambda x: x.microseconds).cumsum()).div(1e6)\n",
    "    \n",
    "    \n",
    "    play_df = play_data[play_data['absoluteYardlineNumber'].notnull()]\n",
    "    #print(play_df.shape)\n",
    "    play_df = play_df[['gameId','playId', 'absoluteYardlineNumber','yardsToGo','personnelD']]\n",
    "\n",
    "    # Merge movement and play-by-play datasets.\n",
    "    df = df.merge(play_df, on=['gameId', 'playId'])\n",
    "\n",
    "    #print(df.columns)\n",
    "    \n",
    "    # Find which teams in the dataframe are offensive vs. defensive.\n",
    "    df['off'] = np.where(df['position'].isin(['QB', 'HB', 'FB', 'WR', 'TE', 'C', 'OG', 'OT', 'RB']),\n",
    "                                                True, False)\n",
    "    print(\"check for any offensive positions not mapped\", df[~df['off']]['position'].unique())\n",
    "\n",
    "    # Extract starting x and y position.\n",
    "    df['x_starting'] = df.groupby(['gameId', 'playId', 'nflId'])['x'].transform(lambda x: x.iloc[0])\n",
    "    df['y_starting'] = df.groupby(['gameId', 'playId', 'nflId'])['y'].transform(lambda x: x.iloc[0])\n",
    "    \n",
    "    # Subtract 10 from yardline to get relative to left endzone.\n",
    "    df['yardline_100'] = df['absoluteYardlineNumber'].sub(10)\n",
    "    \n",
    "    # Extract data for offense, including yardline numbers. Used to find the yardline for the first down.\n",
    "    off_df = df[df['off']].groupby(['gameId', 'playId'])[[\n",
    "        'x_starting', 'yardline_100', 'absoluteYardlineNumber', 'yardsToGo']].first().reset_index()\n",
    "    off_df['yardline_first'] = np.where(off_df['x_starting'].gt(off_df['absoluteYardlineNumber']),\n",
    "            off_df['yardline_100'].sub(off_df['yardsToGo']),\n",
    "            off_df['yardline_100'].add(off_df['yardsToGo']))\n",
    "\n",
    "    # Merge main dataframe with dataframe containing the first down yardline.\n",
    "    # Then extract which side offense is on.\n",
    "    df = df.merge(off_df[['gameId', 'playId', 'yardline_first']].drop_duplicates(), on=['gameId', 'playId'])\n",
    "    df['off_dir'] = np.where(df['yardline_first'].gt(df['yardline_100']),'left', 'right')\n",
    "    \n",
    "    # Adjust starting y coordinate because the perspective would change depending on the side.\n",
    "    df['y_starting_dir'] = np.where(df['off_dir'] == 'right', df['y_starting'].rsub(53.3), df['y_starting'])\n",
    "\n",
    "    #plot_histogram(df, 'y_starting', 50, 'off', 'y_pos_orig')\n",
    "    #plot_histogram(df, 'y_starting_dir', 50, 'off', 'y_pos_notnorm')\n",
    "\n",
    "    # Find starting position of qb and convert to float.\n",
    "    df['y_starting_qb'] = df.groupby(['gameId', 'playId']).apply(lambda x: np.repeat(53.3/2, x.shape[0])\n",
    "        if x[x['position'] == 'QB'].shape[0] == 0 else np.repeat(x[x['position'] == 'QB']['y_starting_dir'].iloc[0], x.shape[0])).explode().values\n",
    "    df['y_starting_qb'] = df['y_starting_qb'].astype(float)\n",
    "\n",
    "    # Find side of qb that player is lined up on.\n",
    "    df['qb_side'] = np.where(df['y_starting_dir'].gt(df['y_starting_qb']), 'R', 'L')\n",
    "\n",
    "    # Find the starting position of each player relative to the qb.\n",
    "    df['y_starting_qb_dir'] = df['y_starting_dir'].sub(df['y_starting_qb'])\n",
    "\n",
    "    # Find the order of positions based on offensive direction.\n",
    "    # First, group and extract first value of the y starting position and direction.\n",
    "    start_df = (df.groupby(['gameId', 'playId', 'position', 'nflId'])[['y_starting_dir', 'off_dir', 'qb_side']].first().reset_index())\n",
    "\n",
    "    # Next, group and extract ranking of positions based on whether team is home or away\n",
    "    # and the starting position.\n",
    "    order_col = np.where(start_df['position'] != 'QB',\n",
    "                        (start_df.groupby(['gameId', 'playId', 'position', 'qb_side'])\n",
    "                        .apply(lambda x: np.where(x.index.get_level_values(-1) == 'R',\n",
    "                                                    find_rank(x, 'y_starting_dir'),\n",
    "                                                    find_rank(x, 'y_starting_dir', reverse=True)))\n",
    "                        .explode()\n",
    "                        .values\n",
    "                        ),\n",
    "                        (start_df.groupby(['gameId', 'playId', 'position'])\n",
    "                        .apply(lambda x: find_rank(x, 'y_starting_dir'))\n",
    "                        .explode()\n",
    "                        .values\n",
    "                        )\n",
    "                        )\n",
    "    # Add column with the position order to the df with indexed starting position.\n",
    "    start_df['pos_order'] = order_col\n",
    "\n",
    "    # Concatenate position and position order to create unique position identifier.\n",
    "    start_df['posId'] = np.where(start_df['position'] != 'QB',\n",
    "                                    start_df['position'].add(start_df['qb_side']).add(start_df['pos_order'].astype(str)),\n",
    "                                    start_df['position'].add(start_df['pos_order'].astype(str)))\n",
    "        \n",
    "\n",
    "    # Merge full dataframe with position number dataframe.\n",
    "    df = df.merge(start_df[['gameId', 'playId', 'nflId', 'posId', 'pos_order']], on=['gameId', 'playId', 'nflId'])\n",
    "\n",
    "    # Use regex to extract personnel from personnel column, and concatenate with main dataframe.\n",
    "    df = pd.concat([df, df['personnelD'].str.extract('(?P<DL>\\d+) DL, (?P<LB>\\d+) LB, (?P<DB>\\d+) DB')], axis=1)\n",
    "\n",
    "    # Find the position of each player relative to the line of scrimmage.\n",
    "    df['x_behind_line'] = np.where(df['off_dir'] == 'right',\n",
    "                                        df['absoluteYardlineNumber'].sub(df['x']),\n",
    "                                        df['x'].sub(df['absoluteYardlineNumber']))\n",
    "\n",
    "\n",
    "    #plot_histogram(df, 'x_behind_line', 50, 'off', 'x_behind_line')\n",
    "\n",
    "    # Extract the yardline for first down and line of scrimmage based on the\n",
    "    # direction that the teams are facing.\n",
    "    df['yardline_first_dir'] = np.where(df['off_dir'] == 'right',\n",
    "                                            df['yardline_first'],\n",
    "                                            df['yardline_first'].rsub(100))\n",
    "    df['yardline_100_dir'] = np.where(df['off_dir'] == 'right',\n",
    "                                            df['yardline_100'],\n",
    "                                            df['yardline_100'].rsub(100))\n",
    "\n",
    "    # Add flag if a player has gone at least 1 yard past the line of scrimmage.\n",
    "    df['exceeded_1yd'] = df.groupby(['gameId', 'playId', 'nflId'])['x_behind_line'].transform(lambda x: x.max() > 1)\n",
    "    \n",
    "    # Use whether player is on offense, whether the player is a QB or WR, and whether a player has\n",
    "    # moved 1 yard beyond the line of scrimmage to determine if the player is a receiver.\n",
    "    df['receiver'] = (df['off'] & (df['position'] != 'QB') & (df['exceeded_1yd'] | (df['position'] == 'WR')))\n",
    "\n",
    "    # Save offensive and defensive numbered position lists.\n",
    "    #off_pos = df[df['off']]['posId'].unique()\n",
    "    #def_pos = df[~df['off']]['posId'].unique()\n",
    "\n",
    "    # Adjust y to match direction of offense.\n",
    "    df['y_dir'] = np.where(df['off_dir'] == 'right', df['y'].rsub(53.3), df['y'])\n",
    "    \n",
    "    #plot_histogram(df, 'y_dir', 50, 'off', 'y_dir_hist')\n",
    "\n",
    "    # Define y coordinates as relative to QB.\n",
    "    df['y_dir_qb'] = df['y_dir'].sub(df['y_starting_qb'])\n",
    "\n",
    "    # The distribution looks centered around 0, as would be expected given that the QB lines up in the center.\n",
    "    #plot_histogram(df, 'y_dir_qb', 50, 'off', 'y_qb_dist')\n",
    "\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_time(df, n_cuts):\n",
    "    # Cut time accumulated into 10 deciles for each play in order to reduce the space. Can adjust number of cuts.\n",
    "    time_cuts = df[['gameId', 'playId', 'time_acc_s']].drop_duplicates().groupby(['gameId', 'playId']).agg(\n",
    "        lambda x: np.nan if x.shape[0] < n_cuts else pd.cut(x, n_cuts, labels=range(1, n_cuts + 1))).explode('time_acc_s')\n",
    "    time_cuts_idx = df[['gameId', 'playId', 'time_acc_s']].drop_duplicates().dropna()\n",
    "    #print(len(time_cuts_idx))\n",
    "    time_cuts_idx = time_cuts_idx[\n",
    "        time_cuts_idx.groupby(['gameId', 'playId'])['time_acc_s'].transform(lambda x: x.shape[0] >= n_cuts)]\n",
    "    #print(len(time_cuts))\n",
    "    #print(len(time_cuts_idx))\n",
    "    time_cuts_idx['time_cut'] = time_cuts.values\n",
    "\n",
    "    df = df.merge(time_cuts_idx, on=['gameId', 'playId', 'time_acc_s'])\n",
    "\n",
    "    # Aggregate by cur.\n",
    "    full_cut_df = df.groupby(['gameId', 'playId', 'posId', 'time_cut']).agg({'y_dir_qb': 'mean', 'x_behind_line': 'mean', 'off': 'first'}).reset_index()\n",
    "\n",
    "    # Find offense and defence and merge.\n",
    "    off_cut_df = full_cut_df[full_cut_df['off']]\n",
    "    def_cut_df = full_cut_df[~full_cut_df['off']]\n",
    "    cut_df = def_cut_df.merge(off_cut_df, on=['gameId', 'playId', 'time_cut'], suffixes=('_def', '_off'))\n",
    "\n",
    "    return df, cut_df\n",
    "\n",
    "def simple_closest_player(df, cut_df):\n",
    "\n",
    "    # Find distance to each offensive player and use to find closest player.\n",
    "    cut_df['distance'] = np.linalg.norm(cut_df[['y_dir_qb_def', 'x_behind_line_def']].values -\n",
    "                cut_df[['y_dir_qb_off', 'x_behind_line_off']].values, axis=1)\n",
    "    cut_df['dist_min'] = cut_df.groupby(['gameId', 'playId', 'posId_def', 'time_cut'])['distance'].transform('min')\n",
    "    \n",
    "    cut_df = cut_df[cut_df['distance'] == cut_df['dist_min']]\n",
    "    cut_df = (cut_df[['gameId', 'playId', 'time_cut', 'posId_def', 'posId_off']]\n",
    "                    .rename({'posId_def': 'posId', 'posId_off': 'pos_off_closest'}, axis=1))\n",
    "    df = df.merge(cut_df, on=['gameId', 'playId', 'time_cut', 'posId'], how='left')\n",
    "\n",
    "    # Next, determine minimum distances between each defensive player and receiver and qb.\n",
    "    # Separate defensive and receiver dataframes.\n",
    "    rec_dis_df = df[df['receiver']]\n",
    "    def_dis_df = df[~df['off']]\n",
    "\n",
    "    # Merge defensive with receiver dataframes on game, play, and time.\n",
    "    dis_df = def_dis_df.merge(rec_dis_df[['gameId', 'playId', 'time_acc_s', 'x_behind_line', 'y_dir_qb']],\n",
    "                on=['gameId', 'playId', 'time_acc_s'],\n",
    "                suffixes=['_def', '_rec'])\n",
    "\n",
    "\n",
    "    # Find distance between each defensive player and each receiver.\n",
    "    dis_df['dist'] = np.linalg.norm(dis_df[['x_behind_line_def', 'y_dir_qb_def']].values -\n",
    "                                                dis_df[['x_behind_line_rec', 'y_dir_qb_rec']].values, axis=1)\n",
    "\n",
    "    # Group dataframe to obtain minimum distance.\n",
    "    min_dis_df = dis_df.groupby(['gameId', 'playId', 'time_acc_s', 'posId'])['dist'].min()\n",
    "    min_dis_df.name = 'min_dist_rec'\n",
    "\n",
    "    # Separate QB dataframe\n",
    "    qb_df = df[df['position'] == 'QB']\n",
    "\n",
    "    # Merge defensive with QB dataframe.\n",
    "    qb_df = def_dis_df.merge(qb_df[['gameId', 'playId', 'time_acc_s', 'x_behind_line', 'y_dir_qb']],\n",
    "                                on=['gameId', 'playId', 'time_acc_s'],\n",
    "                                suffixes=['_def', '_qb'])\n",
    "\n",
    "    # Find distance to the QB.\n",
    "    qb_df['dist'] = np.linalg.norm(qb_df[['x_behind_line_def', 'y_dir_qb_def']].values -\n",
    "                                                qb_df[['x_behind_line_qb', 'y_dir_qb_qb']].values, axis=1)\n",
    "\n",
    "    # Group to form index and distance.\n",
    "    qb_df = qb_df.groupby(['gameId', 'playId', 'time_acc_s', 'posId'])['dist'].min()\n",
    "    qb_df.name = 'dist_qb'\n",
    "\n",
    "    # Concatenate about the same index and reset the index.\n",
    "    min_dist = pd.concat([min_dis_df, qb_df], axis=1).reset_index()\n",
    "\n",
    "    # Merge main dataframe with minimum distance dataframe.\n",
    "    df = df.merge(min_dist, on=['gameId', 'playId', 'time_acc_s', 'posId'], how='left')\n",
    "\n",
    "    # Evaluate whether a receiver is closer than the qb.\n",
    "    df['rec_closer'] = df['min_dist_rec'].lt(df['dist_qb'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_action_by_pos(df):\n",
    "    play_pos_Ids = df.index\n",
    "\n",
    "    action_types = []\n",
    "\n",
    "    for ppId in play_pos_Ids:\n",
    "        \n",
    "        pos = df.loc[ppId]\n",
    "\n",
    "        pos_no_qb = pos[pos['pos_off_closest']!='QB0']\n",
    "        \n",
    "        action = None\n",
    "        \n",
    "        if len(pos) == 1 and pos['pos_off_closest'].values == 'QB0':\n",
    "            action = \"B\"\n",
    "    \n",
    "        if len(pos_no_qb) == 1:\n",
    "            action = \"M\"\n",
    "        else:\n",
    "            action = \"Z\" \n",
    "\n",
    "        if pos[pos.time_cut == pos.time_cut.max()]['pos_off_closest'].values[0] == 'QB0':\n",
    "            action = \"B\"\n",
    "\n",
    "        action_types.append([ppId[0],ppId[1],ppId[2], action])\n",
    "   \n",
    "    return pd.DataFrame(action_types, columns=['gameId','playId','posId','def_action']).set_index(['gameId','playId','posId'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_action_type_df(df):\n",
    "    # Aggregate columns based on game, play, numbered position, and time quartile.\n",
    "    df = df[~df['off'] & (df['position'] != 'TE')].groupby(['gameId', 'playId', 'posId', 'time_cut']).agg(\n",
    "        {'x_starting': 'first', 'y_starting': 'first',\n",
    "        'yardline_100_dir': 'first', 'yardline_first_dir': 'first',\n",
    "        'DL': 'first', 'LB': 'first', 'DB': 'first',\n",
    "        'x_behind_line': 'mean', 'y_dir': 'mean', 'min_dist_rec': 'mean',\n",
    "        'dist_qb': 'mean',\n",
    "        'pos_off_closest': 'first'}\n",
    "    ).reset_index()\n",
    "\n",
    "    action_df = df[['gameId','playId','posId','time_cut','pos_off_closest']]\n",
    "\n",
    "    action_group_df = action_df.groupby(by=['gameId','playId','posId','pos_off_closest']).mean().reset_index().set_index(['gameId','playId','posId'])\n",
    "\n",
    "    #pos = action_group_df.loc[(2018090600,   889,  'MLBR0')]\n",
    "    \n",
    "    #print(pos[pos.time_cut == pos.time_cut.max()]['pos_off_closest'].values[0])\n",
    "\n",
    "    result_df = return_action_by_pos(action_group_df)\n",
    "\n",
    "    result_df = result_df[~result_df.index.duplicated(keep='first')]\n",
    "\n",
    "    review_df = action_df.merge(result_df, on=['gameId', 'playId', 'posId'], how='left')\n",
    "\n",
    "    #complete_df['key'] = complete_df['gameId'].astype(str) + complete_df['playId'].astype(str) + complete_df['posId']\n",
    "    review_df.to_csv('assets/action_type_over_time_cuts.csv')\n",
    "    #complete_df.reset_index().pivot(index=['gameId', 'playId'], columns='posId',values='def_action')\n",
    "\n",
    "    result_df = result_df.reset_index().pivot(index=['gameId', 'playId'], columns='posId',values='def_action')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......reading inputs.......\n",
      "\n",
      ".......starting processing.......\n",
      "...Week 1 loaded...\n",
      "...filtered...\n",
      "check for any offensive positions not mapped ['SS' 'FS' 'MLB' 'CB' 'LB' 'OLB' 'ILB' 'DL' 'DB' 'NT' 'S' 'DE']\n",
      "...transformed...\n",
      "...generated...\n",
      ".....Week 1 COMPLETE.....\n",
      "\n",
      "   100.0% COMPLETE   \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unsupported format character 'M' (0x4d) at index 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m   \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m COMPLETE   \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(percent_complete)))\n\u001b[0;32m     39\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39;49m\u001b[39m--- \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM seconds & counting ---\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m (time\u001b[39m.\u001b[39;49mtime() \u001b[39m-\u001b[39;49m start_time))\n\u001b[0;32m     41\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m output_df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39massets/def_clean_output.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: unsupported format character 'M' (0x4d) at index 5"
     ]
    }
   ],
   "source": [
    "weeks =  range(1,15)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#week_data = pd.read_csv('Kaggle-Data-Files/week1.csv')\n",
    "print('.......reading inputs.......')\n",
    "play_data = pd.read_csv('Kaggle-Data-Files/plays.csv')\n",
    "weeks_data = pd.read_csv('assets/full_position.csv')\n",
    "print('')\n",
    "print('.......starting processing.......')\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "for week in weeks:\n",
    "    week_data = weeks_data[weeks_data['week']==week]\n",
    "    print('...Week {} loaded...'.format(str(week)))\n",
    "    filtered_df = filter_full_position_df(week_data, 11)\n",
    "    print('...filtered...')\n",
    "    transform_df = transform_directions(filtered_df, play_data)\n",
    "    print('...transformed...')\n",
    "    full_df, reduced_df = reduce_time(transform_df, 11)\n",
    "    #print('...reduced...')\n",
    "    simple_df = simple_closest_player(full_df, reduced_df)\n",
    "    #print('...measured...')\n",
    "    action_df = generate_action_type_df(simple_df)\n",
    "    action_df['week'] = week\n",
    "    print('...generated...')\n",
    "    if output_df.empty:\n",
    "        output_df = action_df.copy(deep=True)\n",
    "    else:\n",
    "        output_df.append(action_df)\n",
    "\n",
    "    print('.....Week {} COMPLETE.....'.format(str(week)))\n",
    "    print('')\n",
    "    percent_complete = round(week / len(weeks)*100,2)\n",
    "    print('   {}% COMPLETE   '.format(str(percent_complete)))\n",
    "    print('')\n",
    "    end_time = time.time()\n",
    "    print(\"--- {} minutes elapsed ---\".format(round((end_time - start_time)/60,1)))\n",
    "    print('')\n",
    "output_df.to_csv('assets/def_clean_output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca5c64a504a2343dde48df1b399c6bfb3ece34e1553451ee0c11dd23eea7c960"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
